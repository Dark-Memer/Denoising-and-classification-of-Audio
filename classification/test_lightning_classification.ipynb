{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "H4OmkjFK-JLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NJrNoSA8_xv"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "0kKXgdbt9DeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "audio = zipfile.ZipFile('/content/gdrive/MyDrive/data.zip', 'r')\n",
        "audio.extractall('/content')"
      ],
      "metadata": {
        "id": "VAAopYAx9Dbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from torchmetrics import Accuracy"
      ],
      "metadata": {
        "id": "g3rug-9k9DYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoundDataset(Dataset):\n",
        "\n",
        "    def __init__(self, meta, source_folder, transforms):\n",
        "\n",
        "        self.source_folder = source_folder\n",
        "        self.transforms = transforms\n",
        "        self.meta = meta\n",
        "        self.files = self.meta.path.unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        sound = self.files[i]\n",
        "        sound_df = self.meta.loc[self.meta.path == sound]\n",
        "\n",
        "        if np.random.rand() < 0.5:\n",
        "            label = 0.0\n",
        "            pic_row = sound_df.loc[sound_df.type == 'clean'].iloc[0]\n",
        "        else:\n",
        "            label = 1.0\n",
        "            pic_row = sound_df.loc[sound_df.type == 'noisy'].iloc[0]\n",
        "\n",
        "\n",
        "        pic_path = os.path.join(self.source_folder, pic_row.get('folder'), pic_row.get('type'), str(pic_row.get('id')), sound)\n",
        "\n",
        "        pic = np.expand_dims(np.load(pic_path).astype(float), 2)\n",
        "\n",
        "        augmented = self.transforms(image=pic)\n",
        "\n",
        "        return {'pic': augmented['image'][0].unsqueeze(0).float(), 'label': torch.Tensor([label]).float()}\n",
        "        "
      ],
      "metadata": {
        "id": "xhBedZtZ9DWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightningPredictor(nn.Module):\n",
        "\n",
        "    def __init__(self, test_df, source_folder):\n",
        "        super().__init__()\n",
        "\n",
        "        params=dict(\n",
        "            pooling='avg',\n",
        "            dropout=0.2,\n",
        "            activation='sigmoid',\n",
        "            classes=1)\n",
        "        self.unet = smp.Unet(encoder_name='resnet18', in_channels=1, aux_params = params)\n",
        "        self.loss = {'Accuracy': Accuracy(0.5)}\n",
        "        self.transforms = albu.Compose([albu.PadIfNeeded(480, 80),\n",
        "                                        albu.RandomCrop(480, 80),\n",
        "                                        albu.Resize(576, 96),\n",
        "                                        ToTensorV2()])\n",
        "        self.testset = SoundDataset(test_df, source_folder, self.transforms)\n",
        "        self.testloader = DataLoader(self.testset, batch_size=1, shuffle=False)\n",
        "\n",
        "    def calculate_metrics(self):\n",
        "\n",
        "        Accuracy = list()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(self.testloader):\n",
        "                pic, gt_label = batch['pic'], batch['label']\n",
        "                pr_image, pr_label = self.unet(pic)\n",
        "                Accuracy.append(self.loss['Accuracy'](pr_label, gt_label.type(torch.int64)).detach().numpy())\n",
        "\n",
        "        return np.mean(Accuracy)"
      ],
      "metadata": {
        "id": "TpC07MQJ9O4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/meta_val.csv') # Specify test meta\n",
        "model = LightningPredictor(test_df, '/content/data') # Specify data folder\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/unet_22.pth')) # Specify weights\n",
        "model.eval()\n",
        "metrics = model.calculate_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e0b2ac4cb26f46f381628d1e0c41b317",
            "2b24ef42872442218a9e839576b2d790",
            "b59ad994a9fb45eda1383f352374e263",
            "4f81716ac16b415b84380de36d95ab32",
            "eae215f5b676467196f2a60c395bed05",
            "935af57ca1484f969e62e9b5bc1e9fda",
            "68b02b44a68f41abb587df58ecc3f009",
            "215bb9fea721412b9436ea4de193b001",
            "997581554fab47c6acda6bbb7cc3b61b",
            "4e2258f7169340c7abd4164a667c0d2c",
            "298668a7c6e0445f80673fbbb4329e2f"
          ]
        },
        "id": "48UZsGG90Umt",
        "outputId": "62247a95-d757-45dd-d7c6-71a3a20b7ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0b2ac4cb26f46f381628d1e0c41b317"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy =', metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l54ozhridknf",
        "outputId": "6101a3bd-c449-4974-bef5-c41ed1f5a003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.992\n"
          ]
        }
      ]
    }
  ]
}