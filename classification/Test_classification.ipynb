{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "OT20KLTP59bM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fMkIW8054-S"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install segmentation_models_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import albumentations as albu\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchmetrics import MeanSquaredError\n",
        "from torchmetrics import Accuracy\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "x4Znr_zl6v_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Pbz0jtvb6v8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "audio = zipfile.ZipFile('/content/gdrive/MyDrive/data.zip', 'r')\n",
        "audio.extractall('/content')"
      ],
      "metadata": {
        "id": "5iRyDKf16v6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoundDataset(Dataset):\n",
        "\n",
        "    def __init__(self, meta, source_folder, transforms):\n",
        "\n",
        "        self.source_folder = source_folder\n",
        "        self.transforms = transforms\n",
        "        self.meta = meta\n",
        "        self.files = self.meta.path.unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "\n",
        "        sound = self.files[i]\n",
        "        sound_df = self.meta.loc[self.meta.path == sound]\n",
        "\n",
        "        if np.random.rand() < 0.5:\n",
        "            label = 0.0\n",
        "            pic_row = sound_df.loc[sound_df.type == 'clean'].iloc[0]\n",
        "        else:\n",
        "            label = 1.0\n",
        "            pic_row = sound_df.loc[sound_df.type == 'noisy'].iloc[0]\n",
        "\n",
        "\n",
        "        pic_path = os.path.join(self.source_folder, pic_row.get('folder'), pic_row.get('type'), str(pic_row.get('id')), sound)\n",
        "\n",
        "        pic = np.expand_dims(np.load(pic_path).astype(float), 2)\n",
        "\n",
        "        augmented = self.transforms(image=pic)\n",
        "\n",
        "        return augmented['image'][0].unsqueeze(0).float(), torch.Tensor([label]).float()\n",
        "        "
      ],
      "metadata": {
        "id": "cxN_x3Ub62LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/meta_val.csv') # Specify test meta\n",
        "test_transform = albu.Compose([albu.PadIfNeeded(480, 80),\n",
        "            albu.RandomCrop(480, 80),\n",
        "            albu.Resize(576, 96),\n",
        "            ToTensorV2()])\n",
        "\n",
        "test_dataset = SoundDataset(test_df, '/content/data', transforms = test_transform) # Specify data folder\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                             batch_size=1,\n",
        "                                             num_workers=1)\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "params=dict(\n",
        "            pooling='avg',\n",
        "            dropout=0.2,\n",
        "            activation='sigmoid',\n",
        "            classes=1)\n",
        "model = smp.Unet(encoder_name='resnet18', in_channels=1, aux_params = params).to(device)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/unet_21.pth')) # Specify weights\n",
        "model.eval()\n",
        "\n",
        "metric = Accuracy(0.5).to(device)\n",
        "\n",
        "accuracy_metric = list()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x, y in tqdm(test_loader):\n",
        "\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      pr_image, y_pred = model(x)\n",
        "      accuracy_metric.append(metric(y_pred, y.type(torch.int64)).to('cpu').detach().numpy())\n",
        "\n",
        "print('Accuracy = ', np.mean(accuracy_metric))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "94735455634049708e903345e672e345",
            "56caf885b2be414ab5de9ed451cce504",
            "fd16fe7457a64f94b98fb81da6e7d653",
            "830e2b58bb2244ffa2966ed911bd1e82",
            "be27d3ef30c649eaa0dbd477a7bfbbc2",
            "292119096d974a358a269889407f5ac2",
            "00ea11a91efc44ccada9e9a0835b8bca",
            "07dfd95c5d904d86a1fa40259c403f65",
            "38afb7338b1c46b094ac5e2b6fe7f9ce",
            "6d18fd3c2f4f4edeb246a9c59bd11648",
            "89086650fa894c45b7581526e16c8fb3"
          ]
        },
        "id": "kh0Sl7hPnn-o",
        "outputId": "70d004ba-f622-4a24-dae3-bb7064c4061d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94735455634049708e903345e672e345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.991\n"
          ]
        }
      ]
    }
  ]
}